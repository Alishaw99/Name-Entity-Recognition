{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjWKB8K2YnVx",
        "outputId": "6533b55e-668c-4cfc-fecf-e53f33d90ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2024.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tariq\\miniconda3\\envs\\ner\\lib\\site-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "# Installing transformers library\n",
        "\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4v_1NSK8YvaW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tariq\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries \n",
        "\n",
        "import pandas as pd\n",
        "import torch \n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.optim import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Mix7jNc6Y6tV",
        "outputId": "bed9c4a8-7056-450c-cc0d-42eacac73a53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47954</th>\n",
              "      <td>Opposition leader Mir Hossein Mousavi has said...</td>\n",
              "      <td>O O O B-per I-per O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47955</th>\n",
              "      <td>On Thursday , Iranian state media published a ...</td>\n",
              "      <td>O B-tim O B-gpe O O O O O O O O B-org I-org O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47956</th>\n",
              "      <td>Following Iran 's disputed June 12 elections ,...</td>\n",
              "      <td>O B-geo O O B-tim I-tim O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47957</th>\n",
              "      <td>Since then , authorities have held public tria...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47958</th>\n",
              "      <td>The United Nations is praising the use of mili...</td>\n",
              "      <td>O B-org I-org O O O O O O O O O O O O O O B-ti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  \\\n",
              "47954  Opposition leader Mir Hossein Mousavi has said...   \n",
              "47955  On Thursday , Iranian state media published a ...   \n",
              "47956  Following Iran 's disputed June 12 elections ,...   \n",
              "47957  Since then , authorities have held public tria...   \n",
              "47958  The United Nations is praising the use of mili...   \n",
              "\n",
              "                                                  labels  \n",
              "47954  O O O B-per I-per O O O O O O O O O O O O O O ...  \n",
              "47955  O B-tim O B-gpe O O O O O O O O B-org I-org O ...  \n",
              "47956  O B-geo O O B-tim I-tim O O O O O O O O O O O ...  \n",
              "47957          O O O O O O O O O O O O O O O O O O O O O  \n",
              "47958  O B-org I-org O O O O O O O O O O O O O O B-ti...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Reading csv data\n",
        "\n",
        "df = pd.read_csv('ner.csv')\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vf0tBzMXZcWx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tariq\\miniconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Creating tokenizer intsance\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gM0zKzshZe4Q"
      },
      "outputs": [],
      "source": [
        "# Creating Dataset class\n",
        "\n",
        "label_all_tokens = False\n",
        "\n",
        "def align_label(texts, labels):\n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "class DataSequence(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        lb = [i.split() for i in df['labels'].values.tolist()]\n",
        "        txt = df['text'].values.tolist()\n",
        "        self.texts = [tokenizer(str(i),\n",
        "                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n",
        "        self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_data(self, idx):\n",
        "\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "\n",
        "        return torch.LongTensor(self.labels[idx])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_data = self.get_batch_data(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ffRKNjwgZjYi"
      },
      "outputs": [],
      "source": [
        "# splitting the data into train, test and validation\n",
        "# Defining Unique labels\n",
        "\n",
        "df = df[0:2000]\n",
        "\n",
        "labels = [i.split() for i in df['labels'].values.tolist()]\n",
        "unique_labels = set()\n",
        "\n",
        "for lb in labels:\n",
        "        [unique_labels.add(i) for i in lb if i not in unique_labels]\n",
        "labels_to_ids = {k: v for v, k in enumerate(unique_labels)}\n",
        "ids_to_labels = {v: k for v, k in enumerate(unique_labels)}\n",
        "\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                            [int(.8 * len(df)), int(.9 * len(df))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uFxm0JMpZsfK"
      },
      "outputs": [],
      "source": [
        "# Creating Model class\n",
        "\n",
        "class BertModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BertModel, self).__init__()\n",
        "\n",
        "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n",
        "\n",
        "    def forward(self, input_id, mask, label):\n",
        "\n",
        "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68hQyuwxZvor",
        "outputId": "5d1abbf6-d81b-4198-c1af-b7b0772eb5d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/800 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# Training the model [Transfer learning]\n",
        "\n",
        "def train_loop(model, df_train, df_val):\n",
        "\n",
        "    train_dataset = DataSequence(df_train)\n",
        "    val_dataset = DataSequence(df_val)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    best_acc = 0\n",
        "    best_loss = 1000\n",
        "\n",
        "    for epoch_num in range(EPOCHS):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss, logits = model(input_id, mask, train_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][train_label[i] != -100]\n",
        "              label_clean = train_label[i][train_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_train += acc\n",
        "              total_loss_train += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        for val_data, val_label in val_dataloader:\n",
        "\n",
        "            val_label = val_label.to(device)\n",
        "            mask = val_data['attention_mask'].squeeze(1).to(device)\n",
        "            input_id = val_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            loss, logits = model(input_id, mask, val_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][val_label[i] != -100]\n",
        "              label_clean = val_label[i][val_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_val += acc\n",
        "              total_loss_val += loss.item()\n",
        "\n",
        "        val_accuracy = total_acc_val / len(df_val)\n",
        "        val_loss = total_loss_val / len(df_val)\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n",
        "\n",
        "LEARNING_RATE = 5e-3\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "model = BertModel()\n",
        "train_loop(model, df_train, df_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flo7qqd6ZzKS",
        "outputId": "1c27a91e-f4be-402d-b462-bcf19f11250b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.946\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model\n",
        "\n",
        "def evaluate(model, df_test):\n",
        "\n",
        "    test_dataset = DataSequence(df_test)\n",
        "\n",
        "    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0.0\n",
        "\n",
        "    for test_data, test_label in test_dataloader:\n",
        "\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_data['attention_mask'].squeeze(1).to(device)\n",
        "\n",
        "            input_id = test_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            loss, logits = model(input_id, mask, test_label)\n",
        "\n",
        "            for i in range(logits.shape[0]):\n",
        "\n",
        "              logits_clean = logits[i][test_label[i] != -100]\n",
        "              label_clean = test_label[i][test_label[i] != -100]\n",
        "\n",
        "              predictions = logits_clean.argmax(dim=1)\n",
        "              acc = (predictions == label_clean).float().mean()\n",
        "              total_acc_test += acc\n",
        "\n",
        "    val_accuracy = total_acc_test / len(df_test)\n",
        "    print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n",
        "\n",
        "\n",
        "evaluate(model, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFaET41rcmxA",
        "outputId": "b6a1b85e-1dc0-447b-b3fc-176c427982b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bill Gates is the founder of Microsoft\n",
            "['B-per', 'I-per', 'O', 'O', 'O', 'O', 'B-org']\n"
          ]
        }
      ],
      "source": [
        "# Predicting a sentence\n",
        "\n",
        "def align_word_ids(texts):\n",
        "  \n",
        "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "\n",
        "    for word_idx in word_ids:\n",
        "\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "\n",
        "        elif word_idx != previous_word_idx:\n",
        "            try:\n",
        "                label_ids.append(1)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        else:\n",
        "            try:\n",
        "                label_ids.append(1 if label_all_tokens else -100)\n",
        "            except:\n",
        "                label_ids.append(-100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    return label_ids\n",
        "\n",
        "\n",
        "def evaluate_one_text(model, sentence):\n",
        "\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    mask = text['attention_mask'].to(device)\n",
        "    input_id = text['input_ids'].to(device)\n",
        "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
        "\n",
        "    logits = model(input_id, mask, None)\n",
        "    logits_clean = logits[0][label_ids != -100]\n",
        "\n",
        "    predictions = logits_clean.argmax(dim=1).tolist()\n",
        "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
        "    print(sentence)\n",
        "    print(prediction_label)\n",
        "            \n",
        "evaluate_one_text(model, 'Bill Gates is the founder of Microsoft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4PyFZGgctt0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "vscode": {
      "interpreter": {
        "hash": "e87c311b38e3867b44965d1fc544340be30d9bb75864c35cc64a91cfbbf57e74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
